---
layout:     post
title:      DDIA PART1
subtitle:   数据系统基础
date:       2018-02-10
author:     BY Sunnie
header-img: img/post-bg-2015.jpg
catalog: true
tags:
    - DDIA
---

## 数据系统基础

第一章介绍了应用于数据系统的基本规则：单机还是分布式。

1. 可靠性、可伸展性、可维护性。介绍一些术语以及实现标题目标的思考方法。
2. 数据模型与查询语言。从开发者的角度，比较不同的数据模型和查询语言
3. 存储与检索。探究存储引擎内部。不同存储引擎对于不同的负载采用不同的优化策略，以获得最好的性能。
4. 编码与演进。

### 一 可靠性、可伸展性、可维护性。

如今许多应用是与计算密集型相对的数据密集型，其中**数据量的大小、复杂程度和改变的速度**成为应用需要考虑的问题。

很多数据密集型应用都需要数据库、缓存、查询索引、流处理和批量处理等功能。

#### Thinking about data systems

传统上对于工具有不同的分类，数据库、队列、缓存等等，为什么还需要专门的属于数据系统呢。

首先，为了适应不同情况的使用情形，不同工具种类之间的边界越来越模糊。例如数据存储也用来做消息队列的Redis。

其次，越来越多的应用的需求不能靠单一的工具来满足。例如一个应用需要缓存层、全文搜索，就需要保证这些缓存和索引随时和主数据库保持一致。此时将这些小的组件组合成一个有特殊用途的数据系统，同时保证在主数据库写时的缓存和索引同步更新的一致性。

设计数据系统需要考虑的问题：

* 当系统内部出现问题时，如何保证数据的正确性和完整性？
* 当部分系统崩溃时，如何为用户提供持续的良好的服务？
* 负载上升时如何扩展？
* 一个好的API（application programming interface）有什么特征？

影响数据系统设计的因素：

* 用户的使用方式和体验
* 遗留系统的依赖程度
* etimescale for delivery
* 对于不同种类危险的容错能力
* 监管限制

本书中考虑三个问题，可以通过多种技术、架构和算法来实现这些目标

#### 可靠性

遇到软硬件或者人为错误时候依然有功能和性能的保证。fault是系统的组件错误，failure是系统停止工作。好的容错机制可以避免系统failure，对指定错误的处理，被称为fault-tolerant或者resilient。通常可以通过故意触发错误来进行测试。“*Chaos Monkey*”就是一套用来故意把服务器搞下线的软件，可以测试云环境的恢复能力。在一些不能被修复的情况下，例如黑客入侵或者敏感数据的访问，防止错误是更好的选择。

##### 硬件错误

硬盘崩溃，RAM错误，电缆线停电，误拔网络电缆。硬盘的平均失效前时间是10到50年，在10000硬盘的存储集群上，平均每天都会有一个磁盘错误。

处理方法通常有将磁盘配置为RAID，服务器有双重保障和热插拔功能，数据中心有电池和菜油发电机来提供能量。虽然不能阻止硬件错误的发生，但是可以保证机器在几年内无间断的运行。

一些系统通过软件容错技术可以容忍整个机器的错误，只需要单个节点的下载时间就可以用备份节点来防止整个系统的重新下载。

##### 软件错误

硬件错误通常是随机和相互独立的。而软件错误因为其余多个节点相关，因此更难预测，更容易导致系统崩溃。

* 软件导致bug所有应用服务器崩溃，例如2012年六月30日发现的linux内核bug
* 时空的进程用完所有的共享资源，例如CPU时间，内存，硬盘容量或者网络带宽。
* 服务所依靠的服务减慢，不回应或者返回错误的回应。
* 级联错误

一些可以帮助解决软件中的系统错误：

* 仔细思考系统的消耗的交互
* 全面测试
* 进程分离
* 允许进程崩溃和重启
* 测量
* 监视
* 分析系统行为
* 通过输入输出差异检测（信息队列）

##### 人为错误

结合以下方法来克服人类的不可靠

* 使用错误机会最小化的方式设计系统。例如涉及良好的抽象，API和使得交互界面让做错误输入的可能性减小。
* 将容易出错的地方和容易导致failure的地方分开
* 完整的进行从单元测试到整个系统的集成测试和manual 测试。自动测试是被广泛使用的方法，尤其针对一些常规操作中不会触发的实例。
* 允许从人为错误中快速且简单的修复，来减少失败的影响。例如恢复出厂设置，查看最新修改的代码和重新计算的工具。
* 建立详细清楚的监控，例如性能的度量和错误率。
* 实现良好的管理机制

（为什么我觉得都那么抽象

#### 可扩展性

当数据量、访问量或者复杂度，应该有合理的处理方法。

##### Load

负载参数的选择依赖于系统的架构：每秒网页请求数量、数据库读写次数，同时活跃的用户数量，缓存的访问率。

##### Twitter example

Twitter's main operations are:

Post tweet: A user can publish a new message to their followers.

Home timeline: A user can view tweets posted by the people they follow.

Peak rate for posting tweets: 12000 writes per second. However, the scaling challenge is due to fan-out, which means the complex relationship between users.

Two ways of implementing these two operations:

* Posting a tweet simply insert the new tweet into a global collection. When a user requests the timeline, look up all the people they follow, find all the tweets for each of those users, and merge them.
  * The system struggled to keep up with the load of home timeline queries.
* Maintain a cache for each user's home timeline. When a user posts a tweet, insert the new tweet into each of follower's timeline caches.
  * Average rate of published tweets is two orders of magnitude lower than the rate of home timeline reads.
  * More write time and less read time. Up to 345k writes per second to the home timeline caches.
  * Key load parameter for scalability is the user with 30 million followers.

Tweets from any celebrities that a user may follow are fetched separately and merged with that user's home timeline.

##### Performannce

* How is the performance of your system affected when you increase a load parameter.
* How much do you need to increase the resourses if you want to keep performance unchanged.

We usually care about throughput in a batch processing system.

* The number of records we can process per second
* The total time it takes to run a job on a dataset of a certain size.

**Response time** is what the client sees: time of processsing the request + network delays and queueing delays.

**Latency** is the duration that a request is waiting to be handled.

Iterm **average response time** doesn't include users actually experienced. It's better to use percentiles.

**Median** is the halfway point of response times sorted from fastest to slowest. It's a good metric to know how long users have to wait for a single request.

**Tail latencies** is high percentiles of response times. They directly affect users' experience of the service.



#### 可维护性

高效的对应用进行维护和更新

