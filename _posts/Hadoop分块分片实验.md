title: Hadoop分块分片实验
---

hadoop分块分片实验

<!-- more -->

实验目的：确定一个大文件或者多个小文件在hadoop上mapreduce任务的执行时间与分块分片大小的关系。

环境：3-4节点hadoop

参照组：

默认情况下：（块大小为128且分片大小默认）

1. 一个大文件（大于2G）三个冗余的情况下的存放策略（每个文件占多少个块，冗余在哪些节点上）
   1. 起一个任务的分片数量，map任务的数量，分片大小，花费时间
2. 多个小文件（每个文件不足30M，5个文件以上）三个冗余情况下的存放策略（记录信息同上）
   1. 起一个任务的分片数量，map任务的数量，分片大小，花费时间



块大小为自变量：

分片大小不变，修改块大小为32、64、256

工作同上

Hive.exec.mode.local.auto.tasks.max

分片大小为自变量：

块大小为默认，修改分片大小为块三分之一、一半、三分之二，工作同上





实验结果：mapreduce任务的执行时间与两个变量的关系，图中需要标识出块大小、片大小和map任务数量







