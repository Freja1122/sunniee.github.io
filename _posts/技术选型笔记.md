title: 选型笔记
---

Annn

<!-- more -->

#### 选型结果（太多了hhhh只能说去蹚蹚水，做不完我就舍弃一些。。不知道丢啥）

**全表扫描：Hive+Spark+Hadoop**

（Hive on Spark木有Impala+Hadoop快，但是之后学习机器学习可能spark会用得比较多一点）

（spark可以直接使用sparksql，但是江峰又写了hive，木有梁静茹的勇气直接丢掉）

**事务处理：Phoenix+HBase+Hadoop**



搭建过程：

把hadoop在集群上搭建起来

搭建hive

搭建hbase

增加spark

增加phoenix





##### 解决存储大数据的问题

分布式存储系统：HDFS

##### 解决处理存储后的数据的问题

分布式计算框架：spark（新一代通用计算引擎，内存计算）,mapreduce（离线计算），Tez

##### 解决mapreduce程序员编写不方便的问题

数据仓库：hive（sql来做mr）,pig（脚本来做mr）

##### 解决hive太慢的问题

交互SQL引擎1（直接基于HDFS）：Impala，Presto，Drill

（这些系统让用户更快速地处理SQL任务，牺牲了通用性稳定性等特性。）

交互SQL引擎2（基于Spark）：Hive on Spark和SparkSQL

##### 解决直接取到指定数据而非全表扫描的问题

KV Store：Cassandra，HBase，MongoDB

##### 在HBase上面写sql

关系型数据库层：Phoenix

##### 解决一些特定需求

更特制的系统／组件：Zookeeper（高一致性的分布存取协同系统），Mahout是分布式机器学习库，Protobuf是数据交换的编码和库

##### 保证所有工具有序工作

调度系统：Yarn

![屏幕快照 2017-12-29 上午11.33.24](../../../Desktop/屏幕快照 2017-12-29 上午11.33.24.png)

##### SQL on Hadoop

| 项目名称               | 技术特点                                     | 主导公司                                     |
| ------------------ | ---------------------------------------- | ---------------------------------------- |
| Apache Hive        | 支持原生Hadoop数据存储和访问，存储数据schema等metadada信息，提供类SQL的数据查询语言 | 初期由Facebook开发，现在被Hadoop社区广泛接受            |
| Apache Spark       | 将Map Reduce缓存在内存中执行（RDD，Resilient Distributed Datasets），使用多级有向图来优化查询执行。Spark SQL支持JDBC和ODBC | Databricks                               |
| Cloudera Impala    | 使用C/C++实现的基于Hadoop的数据查询层，用户量比较大，与现有BI工具集成比较好 | Cloudera                                 |
| Stinger Initiative | 基于Hive的性能优化和提升，与Hadoop结合比较紧密             | Hortonworks                              |
| Apache Drill       | 以Google Dremel论文为基础，全新实现的数据查询层，不依赖Hadoop，支持schema free的数据查询。支持JDBC和ODBC | MapR                                     |
| Presto             | 分布式SQL查询执行引擎，支持多种数据源，可扩展性比较好。支持JDBC      | 初期由Facebook开发，现在Netflix也是积极用户和贡献者        |
| Apache Phoenix     | 基于Apache HBase的关系型数据库层。支持JDBC            | 初期由Salesforce开发，现在被多家公司使用和共同开发           |
| Apache Kylin       | 基于Apache HBase的OLAP，使用OLAP Cube技术做多维数据预计算和聚合。支持JDBC | 由ebay开发                                  |
| Apache Tajo        | 基于Hadoop的数据仓库和SQL数据查询执行引擎。支持JDBC         | 由Database Lab., Korea University开发       |
| Cascading Lingual  | 基于Hadoop的SQL数据查询执行引擎。支持JDBC              | 由Cascading和Optiq开源社区开发                   |
| Dato (GraphLab)    | 严格意义上不属于SQL on Hadoop，但是其有特殊的技术，所以值得一提。基于C++实现的数据存储和分析工具，初期是Graph Base的数据存储和查询技术，主要用于机器学习。现在也扩展为通用的大数据分析和处理平台。 | GraphLab由Carnegie Mellon University的Carlos Guestrin教授发起，现在改名为Dato，由dato.com公司主导 |



#### OLTP

联机事务处理OLTP（on-line transaction processing）

OLTP是传统的关系型数据库的主要应用，主要是基本的、日常的事务处理，例如银行交易。

就是比如有10w个用户同时访问这个网站要扛得住并且很快响应



#### OLAP

联机分析处理OLAP（On-Line Analytical Processing）

OLAP是数据仓库系统的主要应用，支持复杂的分析操作，侧重决策支持，并且提供直观易懂的查询结果。



#### Hadoop

了解一哈为什么它经典

##### Hadoop分布式文件系统HDFS被设计成适合运行在通用硬件(commodity hardware)上的分布式文件系统。

- HDFS是一个高度容错性的系统，适合部署在廉价的机器上。
- HDFS能提供高吞吐量的数据访问，非常适合大规模数据集上的应用。
- HDFS放宽了一部分POSIX约束，来实现流式读取文件系统数据的目的。
- HDFS在最开始是作为Apache Nutch搜索引擎项目的基础架构而开发的。
- HDFS是Apache Hadoop Core项目的一部分。

##### Hadoop的局限和不足

- 抽象层次低，需要手工编写代码来完成，使用上难以上手。

- 只提供两个操作，Map和Reduce，表达力欠缺。

- 一个Job只有Map和Reduce两个阶段（Phase），复杂的计算需要大量的Job完成，Job之间的依赖关系是由开发者自己管理的。

- 处理逻辑隐藏在代码细节中，没有整体逻辑

- 中间结果也放在HDFS文件系统中

- ReduceTask需要等待所有MapTask都完成后才可以开始

- 时延高，只适用Batch数据处理，对于交互式数据处理，实时数据处理的支持不够

- 对于迭代式数据处理性能比较差

  ​

#### Hive

hadoop 和 mapreduce 是 hive 架构的根基。

##### Hive 特点

- Hive 最大的特点是 Hive 通过类 SQL 来分析大数据，而避免了写 MapReduce 程序来分析数据，这样使得分析数据更容易
- Hive 是将数据映射成数据库和一张张的表，库和表的元数据信息一般存在关系型数据库上（比如 MySQL）
- Hive 本身并不提供数据的存储功能，数据一般都是存储在 HDFS 上的（对数据完整性、格式要求并不严格）
- Hive 很容易扩展自己的存储能力和计算能力，这个是继承自 hadoop 的（适用于大规模的并行计算）
- Hive 是专为 OLAP 设计，不支持事务

##### Hive缺陷

1. MapReduce：
   1. Map任务结束后，要写磁盘
   2. 一个MapReduce任务结束后，需要将中间结果持久化到HDFS
   3. DAG生成MapReduce任务时，会产生无谓的Map任务
   4. Hadoop在启动MapReduce任务要消耗5-10秒，需要多次启动MapReduce任务



#### Spark

一个快速、通用的大规模数据处理引擎，在Hadoop的整个生态系统中，Spark和MapReduce在同一个层级，即主要解决分布式计算框架的问题

Spark凭借其可伸缩、基于内存计算等特点，以及可以直接读写Hadoop上任何格式数据的优势，进行批处理时更加高效，并有更低的延迟。

Spark已经成为轻量级大数据快速处理的统一平台，各种不同的应用，如实时流处理、机器学习、交互式查询等，都可以通过Spark建立在不同的存储和运行系统上。

以Spark为核心的整个生态圈，最底层为分布式存储系统HDFS、Amazon S3、Mesos，或者其他格式的存储系统（如HBase）；资源管理采用Mesos、YARN等集群资源管理模式，或者Spark自带的独立运行模式，以及本地运行模式。在Spark大数据处理框架中，Spark为上层多种应用提供服务。例如，Spark SQL提供SQL查询服务，性能比Hive快3～50倍；

##### Spark之于Hadoop

Spark是一个计算框架，而Hadoop中包含计算框架MapReduce和分布式文件系统HDFS，Hadoop更广泛地说还包括在其生态系统上的其他系统，如Hbase、Hive等。Spark是MapReduce的替代方案，而且兼容HDFS、Hive等分布式存储层，可融入Hadoop的生态系统，以弥补缺失MapReduce的不足。

##### RDD

弹性分布式数据集（Resilient Distributed Dataset，RDD）：spark的基本计算单元，可以通过一系列算子进行操作（主要有Transformation和Action操作）。

RDD是一个不可修改的，分布的对象集合。每个RDD由多个分区组成，每个分区可以同时在集群中的不同节点上计算。RDD可以包含Python，Java和Scala中的任意对象。

> 如果说，`MapReduce`是公认的分布式数据处理的低层次抽象，类似逻辑门电路中的与门，或门和非门；
> 那么Spark的`RDD`就是分布式大数据处理的高层次抽象，类似逻辑电路中的编码器或译码器等。

##### Spark解决了Hadoop的哪些问题呢？

1. 抽象层次低，需要手工编写代码来完成，使用上难以上手。
   =>基于RDD的抽象，实数据处理逻辑的代码非常简短。。
2. 只提供两个操作，Map和Reduce，表达力欠缺。
   =>提供很多转换和动作，很多基本操作如Join，GroupBy已经在RDD转换和动作中实现。
3. 一个Job只有Map和Reduce两个阶段（Phase），复杂的计算需要大量的Job完成，Job之间的依赖关系是由开发者自己管理的。
   =>一个Job可以包含RDD的多个转换操作，在调度时可以生成多个阶段（Stage），而且如果多个map操作的RDD的分区不变，是可以放在同一个Task中进行。
4. 处理逻辑隐藏在代码细节中，没有整体逻辑
   =>在Scala中，通过匿名函数和高阶函数，RDD的转换支持流式API，可以提供处理逻辑的整体视图。代码不包含具体操作的实现细节，逻辑更清晰。
5. 中间结果也放在HDFS文件系统中
   =>中间结果放在内存中，内存放不下了会写入本地磁盘，而不是HDFS。
6. ReduceTask需要等待所有MapTask都完成后才可以开始
   => 分区相同的转换构成流水线放在一个Task中运行，分区不同的转换需要Shuffle，被划分到不同的Stage中，需要等待前面的Stage完成后才可以开始。
7. 时延高，只适用Batch数据处理，对于交互式数据处理，实时数据处理的支持不够
   =>通过将流拆成小的batch提供Discretized Stream处理流数据。
8. 对于迭代式数据处理性能比较差
   =>通过在内存中缓存数据，提高迭代式计算的性能。

##### Spark特点

- Spark可以部署在YARN上
- Spark原生支持对HDFS文件系统的访问
- 使用Scala语言编写

##### Spark痛点

Spark SQL/DataFrame是Spark用户使用SQL或者DataFrame API构建Spark pipeline的一种选择，并不是一个通用的支持交互式查询的引擎，更多的会用在基于Spark的机器学习任务的数据处理和准备的环节。

SQL支持。Spark的SQL支持没有Hive更全面，bug也相对较多，毕竟是比较新的项目，而且主要是从Spark社区的角度，他们也不是很重视这一方面。Spark SQL的thriftserver的发展也比较慢，因为社区可能更多资源在DataFrame那边。

##### SparkSQL

SparkSQL的前身是Shark，给熟悉RDBMS但又不理解MapReduce的技术人员提供快速上手的工具，hive应运而生，它是当时唯一运行在Hadoop上的SQL-on-hadoop工具。但是MapReduce计算过程中大量的中间磁盘落地过程消耗了大量的I/O，降低的运行效率，为了提高SQL-on-Hadoop的效率，Shark应运而生，但又因为Shark对于Hive的太多依赖（如采用Hive的语法解析器、查询优化器等等),2014年spark团队停止对Shark的开发，将所有资源放SparkSQL项目上

SparkSQL作为Spark生态的一员继续发展，而不再受限于Hive，只是兼容Hive

SparkSQL在架构上和Hive类似，只是底层把MapReduce替换为Spark

##### Hive on Spark

hive跑在spark上，用的是Spark执行引擎，而不是MapReduce

Hive on Spark是一个Hive的发展计划，该计划将Spark作为Hive的底层引擎之一，也就是说，Hive将不再受限于一个引擎，可以采用Map-Reduce、Tez、Spark等引擎。

Hive on Spark是从Hive on MapReduce演进而来，Hive的整体解决方案很不错，但是从查询提交到结果返回需要相当长的时间，查询耗时太长，这个主要原因就是由于Hive原生是基于MapReduce的，那么如果我们不生成MapReduce Job，而是生成Spark Job，就可以充分利用Spark的快速执行能力来缩短HiveQL的响应时间。

##### Hive on Spark与SparkSparkSQL的区别

**hive on spark大体与SparkSQL结构类似，只是SQL引擎不同，但是计算引擎都是spark！**

sparksql和hive on spark时间差不多，但都比hive on mapreduce快很多，官方数据认为spark会被传统mapreduce快10-100倍



目前来看Hive依然是批处理/ETL 类应用的首选。Hive on Spark能够降低Hive的延迟，但是还是达不到交互式BI查询的需求。

目前交互式BI查询最好的选择是Impala。



#### Hbase

Hadoop 主要有三个存储引擎：分别是 Apache HBase、Apache Hadoop HDFS 和 Hadoop Accumulo。

HBase作为面向列的数据库运行在HDFS之上，**HDFS缺乏随即读写操作**，HBase正是为此而出现。HBase以Google BigTable为蓝本，以键值对的形式存储。项目的目标就是快速在主机内数十亿行数据中定位所需的数据并访问它。

想象你在操作RMDB数据库，如果是全表扫描，就用Hive+Hadoop,如果是索引访问，就用HBase+Hadoop 。

用Hadoop作为静态数据仓库，HBase作为数据存储，放那些进行一些操作会改变的数据。



#### Phoenix

Apache Phoenix 项目目标是基于 Apache HBase 提供 OLTP 类型的 SQL，Phoenix 允许用户基于 HBase 数据模型执行插入更新和删除操作，但是就像前面提到的一样，HBase 数据模型从根本上就不同于传统关系型数据库，这样的话 HBase 加 Phoenix 也仍然不是关系型数据库的替代者；



#### parquet

Apache Parquet是Hadoop生态圈中一种**新型列式存储格式**，它可以兼容Hadoop生态圈中大多数计算框架(Hadoop、Spark等)，被多种查询引擎支持(Hive、Impala、Drill等)，并且它是语言和平台无关的。



#### Impala

Impala 是 Cloudera 在受到 Google 的 Dremel 启发下开发的实时交互 SQL 大数据查询工具，Impala 没有再使用缓慢的 Hive+MapReduce 批处理，而是通过使用与商用并行关系数据库中类似的分布式查询引擎（由 Query Planner、Query Coordinator 和 Query Exec Engine 三部分组成），可以直接从 HDFS 或 HBase 中用 SELECT、JOIN 和统计函数查询数据，从而大大降低了延迟。

##### Impala的优缺点

优点：

- 支持SQL查询，快速查询大数据。
- 可以对已有数据进行查询，减少数据的加载，转换。
- 多种存储格式可以选择（Parquet, Text, Avro, RCFile, SequeenceFile）。
- 可以与Hive配合使用。

缺点：

- 不支持用户定义函数UDF。
- 不支持text域的全文搜索。
- 不支持Transforms。
- 不支持查询期的容错。
- 对内存要求高。





#### 总个结

**查询性能上 HIVE<SPARK<IMPALA**

**SQL支持上SPARK<HIVE<IMPALA**



#### TiDB

TiDB 的设计目标是 100% 的 OLTP 场景和 80% 的 OLAP 场景。

看完上面的觉得tp和ap分开管两套系统好复杂，想体验一把一站式。。。。

不过因为云计算要求hadoop，先把hadoop搭建完成再来尝试

##### TiDB Server

TiDB Server 负责接收 SQL 请求，处理 SQL 相关的逻辑，并通过 PD 找到存储计算所需数据的 TiKV 地址，与 TiKV 交互获取数据，最终返回结果。 TiDB Server 是无状态的，其本身并不存储数据，只负责计算，可以无限水平扩展，可以通过负载均衡组件（如LVS、HAProxy 或 F5）对外提供统一的接入地址。

##### PD Server

Placement Driver (简称 PD) 是整个集群的管理模块，其主要工作有三个： 一是存储集群的元信息（某个 Key 存储在哪个 TiKV 节点）；二是对 TiKV 集群进行调度和负载均衡（如数据的迁移、Raft group leader 的迁移等）；三是分配全局唯一且递增的事务 ID。

PD 是一个集群，需要部署奇数个节点，一般线上推荐至少部署 3 个节点。

##### TiKV Server

TiKV Server 负责存储数据，从外部看 TiKV 是一个分布式的提供事务的 Key-Value 存储引擎。存储数据的基本单位是 Region，每个 Region 负责存储一个 Key Range （从 StartKey 到 EndKey 的左闭右开区间）的数据，每个 TiKV 节点会负责多个 Region 。TiKV 使用 Raft 协议做复制，保持数据的一致性和容灾。副本以 Region 为单位进行管理，不同节点上的多个 Region 构成一个 Raft Group，互为副本。数据在多个 TiKV 之间的负载均衡由 PD 调度，这里也是以 Region 为单位进行调度。

基于tikv（一个分布式kv存储引擎）

底下是Facebook的rocksdb

分布式部署+动态增添节点

基于raft的一致性协议

https://www.jianshu.com/p/61a2838ae8db> 单点部署





看看机器性能

mac性能

```
top -l 1 | head -n 10 | grep PhysMem
```

集群的性能

```
free -g
             total       used       free     shared    buffers     cached
Mem:            63          8         54          0          0          2
-/+ buffers/cache:          6         56
Swap:           63         23         40

df -h
文件系统        容量  已用  可用 已用% 挂载点
/dev/sda2       853G  421G  388G   53% /

cat /proc/cpuinfo
processor	: 0
vendor_id	: GenuineIntel
cpu family	: 6
model		: 62
model name	: Intel(R) Xeon(R) CPU E5-2630 v2 @ 2.60GHz
stepping	: 4
microcode	: 0x427
cpu MHz		: 1214.484
cache size	: 15360 KB
physical id	: 0
siblings	: 12
core id		: 0
cpu cores	: 6
apicid		: 0
initial apicid	: 0
fpu		: yes
fpu_exception	: yes
cpuid level	: 13
```